#Python script
#add up the total amount spent for each unique customer, using "customer-orders.csv" 

from pyspark import SparkConf, SparkContext

conf = SparkConf().setMaster("local").setAppName("CustomerOrder")
sc = SparkContext(conf = conf)

def parseLine(line):
    fields = line.split(',')
    ID = int(fields[0])
    amount = float(fields[2])
    return (ID, amount)

lines = sc.textFile("file:///SparkCourse/customer-orders.csv")
rdd = lines.map(parseLine)
totalsByAge = rdd.mapValues(lambda x: x).reduceByKey(lambda x, y: (x + y)).sortByKey()
results = totalsByAge.collect()
for result in results:
    print(result[0], '%.2f' % result[1])



#output

0 5524.95
1 4958.60
2 5994.59

3 4659.63
4 4815.05
5 4561.07
6 5397.88
7 4755.07
8 5517.24
9 5322.65
10 4819.70
11 5152.29
12 4664.59
13 4367.62
14 4735.03
15 5413.51
16 4979.06
17 5032.68
18 4921.27
19 5059.43
20 4836.86
